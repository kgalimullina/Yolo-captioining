{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x0CEpMp3WI07","outputId":"54b2e0bd-3641-4c27-a270-ec434b579165","executionInfo":{"status":"ok","timestamp":1747145404852,"user_tz":-180,"elapsed":2398,"user":{"displayName":"Камилла Галимуллина","userId":"10056740244410670921"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/project/extra_flowers.zip'"],"metadata":{"id":"fGJjw7wQWJbc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install ultralytics"],"metadata":{"id":"22L9WVP6iF0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","import cv2\n","import os\n","import zipfile\n","from tqdm import tqdm\n","import shutil\n","import yaml\n","from sklearn.model_selection import train_test_split\n","from ultralytics import YOLO\n","import torch"],"metadata":{"id":"Isn0ZliohrbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean_unzip(zip_path, output_dir):\n","    \"\"\"Распаковывает архив, игнорируя технические файлы Mac и лишнюю вложенность\"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        # Фильтрация: только нужные файлы (images/, labels/)\n","        valid_files = [\n","            f for f in zip_ref.namelist()\n","            if (f.startswith('extra_flowers/images/')\n","                or f.startswith('extra_flowers/labels/'))\n","            and not ('__MACOSX' in f or '._' in f or '.DS_Store' in f)\n","        ]\n","\n","        # Распаковка с прогресс-баром\n","        for file in tqdm(valid_files, desc=\"Распаковка\"):\n","            try:\n","                # Удаляем 'extra_flowers/' из пути\n","                dest_path = file.replace('extra_flowers/', '')\n","                # Полный путь для сохранения\n","                full_path = os.path.join(output_dir, dest_path)\n","\n","                # Создаем папки, если их нет\n","                os.makedirs(os.path.dirname(full_path), exist_ok=True)\n","\n","                # Извлекаем только если это файл (не папка)\n","                if not file.endswith('/'):\n","                    with zip_ref.open(file) as src, open(full_path, 'wb') as dst:\n","                        dst.write(src.read())\n","            except Exception as e:\n","                print(f\"Ошибка с {file[:50]}...: {str(e)[:50]}\")\n","\n","# Запуск\n","clean_unzip('/content/drive/MyDrive/project/extra_flowers.zip', '/content/extra_flowers')\n","\n","# Дополнительная очистка\n","!find clean_data -name '__MACOSX' -exec rm -rf {} + 2>/dev/null\n","!find clean_data -name '.DS_Store' -delete 2>/dev/null\n","!find clean_data -name '._*' -delete 2>/dev/null\n","\n","print(\"Готово! Структура:\")\n","!tree clean_data -L 2"],"metadata":{"id":"juZQ6o9VsMln","colab":{"base_uri":"https://localhost:8080/"},"outputId":"98ec3cef-c83f-42e7-8d44-3ea6e8c75856","executionInfo":{"status":"ok","timestamp":1747145502188,"user_tz":-180,"elapsed":2772,"user":{"displayName":"Камилла Галимуллина","userId":"10056740244410670921"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Распаковка: 100%|██████████| 1473/1473 [00:02<00:00, 652.56it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Готово! Структура:\n","/bin/bash: line 1: tree: command not found\n"]}]},{"cell_type":"code","source":["#!rm -r extra_flowers/"],"metadata":{"id":"eVVgRH8qa4f9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================\n","# 1. НАСТРОЙКИ ПУТЕЙ\n","# ======================\n","DATA_SOURCE = \"/content/extra_flowers\"\n","DATA_DEST = \"/content/datasets/extra_flowers\"\n","CLASS_NAMES = [\n","    \"Bellflower\", \"Black-eyed Susan\", \"Calendula\", \"California poppy\",\n","    \"Carnation\", \"Daffodil\", \"Daisy\", \"Dandelion\", \"Iris\", \"Magnolia\",\n","    \"Rose\", \"Sunflower\", \"Tulip\", \"Water lily\"\n","]\n","TRAIN_RATIO = 0.8\n","\n","# ======================\n","# 2. СОЗДАЕМ СТРУКТУРУ ПАПОК\n","# ======================\n","os.makedirs(f\"{DATA_DEST}/extra_flowers/train/images\", exist_ok=True)\n","os.makedirs(f\"{DATA_DEST}/extra_flowers/train/labels\", exist_ok=True)\n","os.makedirs(f\"{DATA_DEST}/extra_flowers/val/images\", exist_ok=True)\n","os.makedirs(f\"{DATA_DEST}/extra_flowers/val/labels\", exist_ok=True)\n","\n","# ======================\n","# 3. ПРОВЕРКА ИСХОДНЫХ ДАННЫХ\n","# ======================\n","def validate_data_structure():\n","    \"\"\"Проверяет соответствие изображений и разметок\"\"\"\n","    images = [f for f in os.listdir(f\"{DATA_SOURCE}/images\")\n","             if f.lower().endswith(('.jpg', '.png', '.jpeg', '.webp'))]\n","    missing = []\n","\n","    for img in images:\n","        label = os.path.splitext(img)[0] + \".txt\"\n","        if not os.path.exists(f\"{DATA_SOURCE}/labels/{label}\"):\n","            missing.append(img)\n","\n","    if missing:\n","        print(f\"Найдено {len(missing)} изображений без разметки!\")\n","        return [img for img in images if img not in missing]\n","    return images\n","\n","valid_images = validate_data_structure()\n","\n","# ======================\n","# 4. РАЗДЕЛЕНИЕ НА TRAIN/VAL\n","# ======================\n","train_files, val_files = train_test_split(valid_images, train_size=TRAIN_RATIO, random_state=42)\n","\n","def copy_files(file_list, subset):\n","    \"\"\"Копирует файлы с соблюдением структуры YOLO\"\"\"\n","    for img in file_list:\n","        # Изображения\n","        shutil.copy(\n","            f\"{DATA_SOURCE}/images/{img}\",\n","            f\"{DATA_DEST}/extra_flowers/{subset}/images/{img}\"\n","        )\n","        # Разметки\n","        label = os.path.splitext(img)[0] + \".txt\"\n","        if os.path.exists(f\"{DATA_SOURCE}/labels/{label}\"):\n","            shutil.copy(\n","                f\"{DATA_SOURCE}/labels/{label}\",\n","                f\"{DATA_DEST}/extra_flowers/{subset}/labels/{label}\"\n","            )\n","\n","copy_files(train_files, \"train\")\n","copy_files(val_files, \"val\")\n","\n","# ======================\n","# 5. СОЗДАНИЕ data.yaml\n","# ======================\n","data_yaml = {\n","    \"train\": f\"{DATA_DEST}/extra_flowers/train/images\",\n","    \"val\": f\"{DATA_DEST}/extra_flowers/val/images\",\n","    \"nc\": len(CLASS_NAMES),\n","    \"names\": CLASS_NAMES\n","}\n","\n","with open(f\"{DATA_DEST}/data.yaml\", \"w\") as f:\n","    yaml.dump(data_yaml, f)\n","\n","# ======================\n","# 6. ПРОВЕРКА РЕЗУЛЬТАТА\n","# ======================\n","print(f\"\\n✅ Готово! Итоговая структура:\")\n","print(f\"Общее изображений: {len(valid_images)}\")\n","print(f\"Train: {len(train_files)}\")\n","print(f\"Val: {len(val_files)}\")\n","print(f\"YAML: {DATA_DEST}/data.yaml\\n\")\n","\n","# Проверка первых 5 файлов\n","!ls {DATA_DEST}/extra_flowers/train/images | head -5"],"metadata":{"id":"4gsFFv72a3Od","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc7176ea-ece1-4e90-d4a0-ffcf5e44c699","executionInfo":{"status":"ok","timestamp":1747145505832,"user_tz":-180,"elapsed":3610,"user":{"displayName":"Камилла Галимуллина","userId":"10056740244410670921"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","✅ Готово! Итоговая структура:\n","Общее изображений: 735\n","Train: 588\n","Val: 147\n","YAML: /content/datasets/extra_flowers/data.yaml\n","\n","0010fef3-yz-ylt-dem-magnoliya-g-l.jpg\n","0138b2a1-40612281740_e65e4e1a65_b.jpg\n","01d087bf-000036.jpg\n","027be676-xqU02QOq-bk.jpg\n","03566105-6478256.jpg\n"]}]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/yolo_results_3/weights/best.pt\"\n","model = YOLO(path).to('cuda')"],"metadata":{"id":"k37EUQ8znp_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_args = {\n","    'data': '/content/datasets/extra_flowers/data.yaml',\n","    'epochs': 20,\n","    'imgsz': 640,\n","    'batch': 32,                  # Максимально возможный для вашего GPU\n","    'device': 'cuda',             # Явное указание GPU\n","    'lr0': 0.001,                 # Пониженный learning rate для дообучения\n","    'patience': 15,               # Ранняя остановка при отсутствии улучшений\n","    'optimizer': 'AdamW',         # Лучше для специфичных классов\n","    'augment': True,              # Критично для цветов!\n","    'hsv_h': 0.02,                # Усиленная аугментация оттенков\n","    'flipud': 0.3,                # Вертикальное отражение\n","    'name': 'flowers_finetune',\n","    'exist_ok': True,             # Перезапись предыдущих результатов\n","    'pretrained': True            # Использовать предобученные веса\n","}\n","\n","# Запуск дообучения\n","results = model.train(**train_args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R9_iTPGrYayO","outputId":"d790bf68-6dbe-4520-90a7-e2f17394ea6c","executionInfo":{"status":"ok","timestamp":1747145993097,"user_tz":-180,"elapsed":484660,"user":{"displayName":"Камилла Галимуллина","userId":"10056740244410670921"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.133 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/datasets/extra_flowers/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.3, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.02, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/yolo_results_3/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=flowers_finetune, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/flowers_finetune, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754042  ultralytics.nn.modules.head.Detect           [14, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,578 parameters, 3,013,562 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.35M/5.35M [00:00<00:00, 303MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2487.4±747.2 MB/s, size: 529.8 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/extra_flowers/extra_flowers/train/labels.cache... 588 images, 0 backgrounds, 0 corrupt: 100%|██████████| 588/588 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1058, len(boxes) = 2298. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 494.3±126.6 MB/s, size: 240.8 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/extra_flowers/extra_flowers/val/labels.cache... 147 images, 0 backgrounds, 0 corrupt: 100%|██████████| 147/147 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 185, len(boxes) = 483. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/flowers_finetune/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/flowers_finetune\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/20       4.9G      1.303      1.129      1.273        110        640: 100%|██████████| 19/19 [00:29<00:00,  1.55s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.702      0.377      0.417      0.261\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/20      5.46G       1.31      1.169       1.26        150        640: 100%|██████████| 19/19 [00:31<00:00,  1.67s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.651        0.5      0.556      0.339\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/20      5.46G      1.336      1.228       1.28         85        640: 100%|██████████| 19/19 [00:21<00:00,  1.13s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.769      0.534      0.642      0.382\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/20      5.46G      1.294        1.1       1.25         95        640: 100%|██████████| 19/19 [00:19<00:00,  1.02s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.536      0.636      0.623      0.372\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/20      6.16G      1.336      1.117      1.252        113        640: 100%|██████████| 19/19 [00:18<00:00,  1.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.742      0.616      0.687      0.418\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/20      6.16G       1.35      1.123       1.29         68        640: 100%|██████████| 19/19 [00:17<00:00,  1.11it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483       0.73      0.583      0.669      0.416\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/20      6.16G      1.318      1.102       1.27         67        640: 100%|██████████| 19/19 [00:17<00:00,  1.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.688      0.585      0.642      0.402\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/20      6.16G      1.311      1.136      1.262        115        640: 100%|██████████| 19/19 [00:16<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483       0.75      0.632      0.723      0.447\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/20      6.16G      1.287      1.074      1.261         98        640: 100%|██████████| 19/19 [00:17<00:00,  1.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.764      0.606      0.682      0.435\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/20      6.16G      1.273      1.072      1.242         86        640: 100%|██████████| 19/19 [00:17<00:00,  1.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483       0.65      0.695      0.695      0.457\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/20      6.16G      1.307       1.07      1.288         39        640: 100%|██████████| 19/19 [00:24<00:00,  1.30s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.754      0.612      0.696      0.452\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/20      6.16G      1.264      1.014       1.28         22        640: 100%|██████████| 19/19 [00:16<00:00,  1.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.776      0.599        0.7      0.454\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/20      6.16G      1.292     0.9639      1.284         40        640: 100%|██████████| 19/19 [00:16<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.50it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.669      0.669        0.7      0.454\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/20      6.16G      1.258     0.9788      1.285         19        640: 100%|██████████| 19/19 [00:16<00:00,  1.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.755      0.627      0.726      0.467\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/20      6.16G      1.223     0.9288      1.259         22        640: 100%|██████████| 19/19 [00:16<00:00,  1.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.738       0.69      0.727       0.47\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/20      6.16G      1.241     0.8746      1.259         52        640: 100%|██████████| 19/19 [00:16<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.762      0.645      0.715      0.465\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/20      6.16G      1.196     0.8344      1.221         46        640: 100%|██████████| 19/19 [00:16<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.791      0.678       0.74      0.486\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/20      6.16G        1.2     0.8516      1.233         50        640: 100%|██████████| 19/19 [00:18<00:00,  1.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.819      0.667      0.755       0.49\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/20      6.16G      1.172     0.7977      1.203         43        640: 100%|██████████| 19/19 [00:15<00:00,  1.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483      0.832      0.672      0.759      0.502\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/20      6.17G      1.146     0.7631      1.194         44        640: 100%|██████████| 19/19 [00:16<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483        0.8      0.703      0.777      0.508\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","20 epochs completed in 0.127 hours.\n","Optimizer stripped from runs/detect/flowers_finetune/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/flowers_finetune/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/flowers_finetune/weights/best.pt...\n","Ultralytics 8.3.133 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 3,008,378 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.21s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        147        483       0.81      0.697      0.774      0.509\n","            Bellflower         16         55      0.639      0.345      0.461        0.2\n","      Black-eyed Susan          4         17      0.873      0.647      0.799      0.375\n","             Calendula          7         21      0.622      0.476      0.566      0.273\n","      California poppy          9         35      0.879      0.629      0.801      0.378\n","             Carnation         14         71      0.771      0.704      0.784      0.413\n","              Daffodil         12         46      0.836      0.543      0.656      0.291\n","                 Daisy         18         53      0.793      0.528      0.632      0.316\n","             Dandelion          6          8      0.887      0.983      0.967      0.788\n","                  Iris         13         21      0.821       0.81      0.833      0.669\n","              Magnolia         10         19       0.81      0.899      0.933      0.755\n","                  Rose         14         63      0.771      0.714      0.779       0.54\n","             Sunflower          6         23      0.891      0.652      0.752      0.596\n","                 Tulip          8         39      0.843      0.824      0.879      0.653\n","            Water lily         10         12      0.908          1      0.995      0.884\n","Speed: 0.2ms preprocess, 7.3ms inference, 0.0ms loss, 3.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/flowers_finetune\u001b[0m\n"]}]},{"cell_type":"code","source":["# Сохранение модели\n","torch.save(model.state_dict(), 'fine_tuned_flowers.pt')"],"metadata":{"id":"VvDU6p91Ym5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cp -r runs/detect/flowers_finetune /content/drive/MyDrive/yolo_results_3"],"metadata":{"id":"ZvdccX4Wjgi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Путь к архиву\n","zip_path = '/content/drive/MyDrive/dataset_flowers/flowers_120.v1i.yolov8.zip'\n","extract_to = '/content/flowers'\n","\n","# Распаковка\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_to)\n","\n","print(\"Архив распакован в:\", extract_to)"],"metadata":{"id":"XZ-QHbKniUE3","executionInfo":{"status":"ok","timestamp":1747145996773,"user_tz":-180,"elapsed":3173,"user":{"displayName":"Камилла Галимуллина","userId":"10056740244410670921"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee05b0a1-53b1-43e4-f666-14c8d6c26910"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Архив распакован в: /content/flowers\n"]}]},{"cell_type":"code","source":["!yolo val model=/content/drive/MyDrive/yolo_results_3/weights/best.pt data=/content/flowers/data.yaml split=test name=test_results save_json=True save_hybrid=True\n"],"metadata":{"id":"I0Eg8KqflblI","executionInfo":{"status":"ok","timestamp":1747146018376,"user_tz":-180,"elapsed":21553,"user":{"displayName":"Камилла Галимуллина","userId":"10056740244410670921"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"af0c7d02-00a9-4ab2-c01d-518276eea640"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ 'save_hybrid' is deprecated and will be removed in in the future.\n","Ultralytics 8.3.133 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 3,008,378 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 981.4±279.5 MB/s, size: 36.4 KB)\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/flowers/test/labels.cache... 168 images, 1 backgrounds, 0 corrupt: 100% 168/168 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:06<00:00,  1.60it/s]\n","                   all        168        196      0.281      0.263      0.201      0.148\n","            Bellflower         14         18       0.17      0.111     0.0798     0.0593\n","      Black-eyed Susan         14         19      0.148     0.0234     0.0764     0.0438\n","             Calendula         15         15          0          0     0.0785     0.0618\n","      California poppy         13         17      0.317      0.588      0.334       0.23\n","             Carnation         14         14          1          0     0.0371     0.0309\n","              Daffodil         11         13      0.395     0.0607      0.085     0.0447\n","                 Daisy         12         15      0.599      0.333      0.355      0.241\n","             Dandelion          9          9     0.0637      0.444     0.0791     0.0525\n","                  Iris         10         10      0.153        0.4       0.29      0.246\n","              Magnolia          8          8     0.0653      0.158     0.0503     0.0315\n","                  Rose          8          9      0.365      0.321      0.314      0.242\n","             Sunflower         17         19      0.133      0.211      0.227      0.183\n","                 Tulip         11         19       0.13      0.684      0.333      0.282\n","            Water lily         11         11      0.389      0.348      0.469      0.321\n","Speed: 11.3ms preprocess, 8.6ms inference, 0.0ms loss, 5.9ms postprocess per image\n","Saving runs/detect/test_results3/predictions.json...\n","Results saved to \u001b[1mruns/detect/test_results3\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}]},{"cell_type":"markdown","source":["тут проверка на новых картинках"],"metadata":{"id":"CpMyO3CviUMy"}},{"cell_type":"code","source":["# Пути\n","model_path = \"/content/drive/MyDrive/yolo_results_3/weights/best.pt\"\n","source_dir = \"/content/drive/MyDrive/detect/\"\n","output_dir = \"/content/results\"  # Новая папка для всех результатов\n","\n","# Создаем папку для результатов, если её нет\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Список файлов\n","file_names = [\n","    \"waterlily.jpg\", \"tulip3.jpg\", \"sunflower.jpg\", \"rose.jpg\", \"magnolia.jpg\",\n","    \"iris2.jpg\", \"dandelion.jpg\", \"daisy2.jpg\", \"daffodil.jpg\", \"carnation.jpg\",\n","    \"californiapoppy2.jpg\", \"calendula.jpg\", \"blackeye.jpg\", \"bellflower.jpg\"\n","]\n","\n","for file_name in file_names:\n","    source_path = os.path.join(source_dir, file_name)\n","\n","    if not os.path.exists(source_path):\n","        print(f\"Файл {file_name} не найден, пропускаем...\")\n","        continue\n","\n","    print(f\"\\nОбработка {file_name}...\")\n","\n","    # Запуск предсказания с явным указанием папки для сохранения\n","    !yolo predict model={model_path} source={source_path} save=True project={output_dir} name=\"predict\" exist_ok=True\n","\n","    # Путь к результату\n","    output_path = os.path.join(output_dir, \"predict\", file_name)\n","\n","    if os.path.exists(output_path):\n","        img = cv2.imread(output_path)\n","        cv2_imshow(img)\n","        print(f\"Результат для {file_name} успешно загружен.\")\n","    else:\n","        print(f\"Ошибка: результат для {file_name} не найден.\")\n","        !ls {os.path.join(output_dir, \"predict\")}  # Проверим содержимое папки"],"metadata":{"id":"Y3corF1A2nXh","executionInfo":{"status":"ok","timestamp":1747146104494,"user_tz":-180,"elapsed":86108,"user":{"displayName":"Камилла Галимуллина","userId":"10056740244410670921"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"16pbus1YPE3Dda0Wxi_tp-N3AMUUgN6k3"},"outputId":"e9d53306-db66-41f2-8d69-a10c7efdf55b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# 1. Подключение Google Диска\n","drive.mount('/content/drive')\n","\n","# 2. Пути\n","target_dir = \"/content/drive/MyDrive/project\"\n","os.makedirs(f\"{target_dir}/predictions\", exist_ok=True)\n","os.makedirs(f\"{target_dir}/metrics\", exist_ok=True)\n","\n","# 3. Копирование предсказаний\n","if os.path.exists(\"/content/results/predict\"):\n","    !cp -r /content/results/predict/* \"{target_dir}/predictions/\"\n","    print(\"Предсказания скопированы!\")\n","else:\n","    print(\"Папка /content/results/predict не найдена.\")\n","\n","# 4. Копирование метрик\n","if os.path.exists(\"/content/runs/detect/flowers_finetune\"):\n","    !cp -r /content/runs/detect/flowers_finetune/* \"{target_dir}/metrics/\"\n","    print(\"Метрики скопированы!\")\n","else:\n","    print(\"Папка /content/runs/detect/flowers_finetune не найдена.\")\n","\n","# 5. Итоговая проверка\n","print(\"\\nИтоговое содержимое папки project:\")\n","!ls -la \"{target_dir}\""],"metadata":{"id":"E7_PE73LzOWi","executionInfo":{"status":"ok","timestamp":1747146188671,"user_tz":-180,"elapsed":2203,"user":{"displayName":"Камилла Галимуллина","userId":"10056740244410670921"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"248c94cb-592c-449b-9e9b-98641a01d3c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Предсказания скопированы!\n","Метрики скопированы!\n","\n","Итоговое содержимое папки project:\n","total 291847\n","-rw------- 1 root root 298791196 May 13 11:56  extra_flowers.zip\n","drwx------ 3 root root      4096 May 13 14:23  metrics\n","drwx------ 2 root root      4096 May 13 14:23  predictions\n","-rw------- 1 root root     51635 May 13 14:22 'Untitled11 (1).ipynb'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gtEaBsMsq-2-"},"execution_count":null,"outputs":[]}]}